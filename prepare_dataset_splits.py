"""
Create train/val/test directories for the CBIS-DDSM mass subset after running
the preprocessing pipeline on the Kaggle JPEG release.

This script matches each processed PNG file to its pathology label using the
merged metadata produced by pathology.py (all_mass_pathology.csv). It then
splits the dataset with stratified sampling and copies images into folders
compatible with model_development_and_evaluation.py.

Usage example:

    python prepare_dataset_splits.py \
        --images-root /Users/.../processed_png/train_augmented \
        --metadata /Users/.../processed_png/all_mass_pathology.csv \
        --output-root /Users/.../processed_png/dataset_splits \
        --val-size 0.1 \
        --test-size 0.1

DEPRECATED (revival):
This script is kept for reference, but the repo is moving to a manifest-first workflow:
  1) Build a canonical manifest from CBIS-DDSM metadata:
       python scripts/build_manifest_from_cbis_csv.py --mass-train-csv ... --mass-test-csv ... --out-manifest manifest.csv
  2) Assign patient-level splits (anti-leakage):
       python scripts/assign_splits.py --in-manifest manifest.csv --out-manifest manifest_splits.csv
  3) Materialize torchvision ImageFolder layout when images exist:
       python scripts/materialize_imagefolder.py --manifest manifest_splits.csv --output-root dataset_splits --mode symlink
"""

from __future__ import annotations

import argparse
import shutil
from pathlib import Path

import pandas as pd
from sklearn.model_selection import train_test_split


VALID_PATHOLOGIES = {"BENIGN", "MALIGNANT"}


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="Split processed PNGs into train/val/test folders.")
    parser.add_argument(
        "--images-root",
        type=Path,
        default=Path("/Users/saujanyathapaliya/Documents/breastcancer/processed_png/train_no_white"),
        help="Folder that contains the cleaned PNGs you want to split (default: train_no_white).",
    )
    parser.add_argument(
        "--metadata",
        type=Path,
        default=Path("/Users/saujanyathapaliya/Documents/breastcancer/processed_png/all_mass_pathology.csv"),
        help="Path to all_mass_pathology.csv generated by pathology.py.",
    )
    parser.add_argument(
        "--output-root",
        type=Path,
        default=Path("/Users/saujanyathapaliya/Documents/breastcancer/processed_png/dataset_splits"),
        help="Destination root where train/val/test folders will be created.",
    )
    parser.add_argument("--val-size", type=float, default=0.1, help="Fraction of data to reserve for validation.")
    parser.add_argument("--test-size", type=float, default=0.1, help="Fraction of data to reserve for testing.")
    parser.add_argument("--seed", type=int, default=42, help="Random seed for reproducible splits.")
    parser.add_argument(
        "--copy-mode",
        choices=["copy", "symlink"],
        default="copy",
        help="Whether to copy files (default) or create symlinks in the split folders.",
    )
    return parser.parse_args()


def load_metadata(metadata_path: Path) -> pd.DataFrame:
    df = pd.read_csv(metadata_path)
    df = df[df["pathology"].isin(VALID_PATHOLOGIES)].copy()
    # crop_name column matches the prefix of our processed PNG filenames.
    df.rename(columns={"crop_name": "image_prefix"}, inplace=True)
    return df[["image_prefix", "pathology"]]


def collect_images(images_root: Path) -> pd.DataFrame:
    records = []
    for file_path in images_root.glob("*.png"):
        stem = file_path.stem
        if "_1.3." not in stem:
            continue
        prefix = stem.split("_1.3.", 1)[0]
        records.append({"image_prefix": prefix, "file_path": file_path})
    return pd.DataFrame(records)


def stratified_split(df: pd.DataFrame, val_size: float, test_size: float, seed: int):
    train_val, test = train_test_split(
        df, test_size=test_size, stratify=df["pathology"], random_state=seed
    )
    adjusted_val_size = val_size / (1 - test_size)
    train, val = train_test_split(
        train_val, test_size=adjusted_val_size, stratify=train_val["pathology"], random_state=seed
    )
    return train, val, test


def stage_split(split_df: pd.DataFrame, split_name: str, output_root: Path, copy_mode: str) -> None:
    for label in VALID_PATHOLOGIES:
        (output_root / split_name / label).mkdir(parents=True, exist_ok=True)

    for row in split_df.itertuples(index=False):
        dest = output_root / split_name / row.pathology / row.file_path.name
        if copy_mode == "copy":
            shutil.copy2(row.file_path, dest)
        else:
            if dest.exists():
                dest.unlink()
            dest.symlink_to(row.file_path)


def main() -> None:
    args = parse_args()
    metadata = load_metadata(args.metadata)
    images_df = collect_images(args.images_root)
    merged = pd.merge(images_df, metadata, on="image_prefix", how="inner")

    if merged.empty:
        raise RuntimeError("No images matched metadata. Check that filenames still contain the patient IDs.")

    train_df, val_df, test_df = stratified_split(merged, args.val_size, args.test_size, args.seed)
    args.output_root.mkdir(parents=True, exist_ok=True)

    stage_split(train_df, "train", args.output_root, args.copy_mode)
    stage_split(val_df, "val", args.output_root, args.copy_mode)
    stage_split(test_df, "test", args.output_root, args.copy_mode)

    print(
        f"Split complete. train={len(train_df)}, val={len(val_df)}, test={len(test_df)} "
        f"saved under {args.output_root}"
    )


if __name__ == "__main__":
    main()
